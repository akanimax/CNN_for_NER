{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding of Text\n",
    "================\n",
    "\n",
    "The goal of this script is to train a Word2Vec skip-gram model over the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the paths required for the data here:\n",
    "\n",
    "root_path = \"../Data\"\n",
    "train_path = os.path.join(root, \"Train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: read the data from the data file and convert it into a well formatted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to read the data from the file and store it in a well formatted lists\n",
    "\n",
    "def read_data(filename):\n",
    "    \"\"\" store the file data as a list of words\n",
    "    \n",
    "        input: path of the data file\n",
    "        output: data list, labels, sentence_completion_mark\n",
    "        \n",
    "    \"\"\"\n",
    "    data = [] # actual words \n",
    "    labels = [] # keep the track of the labels of the data\n",
    "    sentence_mark = [] # integers to keep track of the end of sentence\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        # tf.compat makes the string data compatible with tensorflow\n",
    "        count = 0; \n",
    "        for line in f:\n",
    "            \n",
    "            line = line.strip() # strip it off the newline character\n",
    "            \n",
    "            if(line == \"\"):\n",
    "                sentence_mark.append(count)\n",
    "            else: \n",
    "                data_point = tf.compat.as_str(line).split(\"\\t\") # split at the tab character\n",
    "                data.append(data_point[0]) # the word in data\n",
    "                labels.append(data_point[1]) # the label in labels list\n",
    "\n",
    "            # increment counter:\n",
    "            count += 1\n",
    "    \n",
    "    return data, labels, sentence_mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 46469\n",
      "Some of the sample words in the vocabulary:  ['me', '*wink*', 'Made', 'it', 'back', 'home', 'to', 'GA', '.', 'It', 'sucks', 'not', 'to', 'be', 'at', 'Disney', 'world', ',', 'but', 'its', 'good', 'to', 'be', 'home', '.', 'Time', 'to', 'start', 'planning', 'the', 'next', 'Disney', 'World', 'trip', '.', \"'\", 'Breaking', 'Dawn', \"'\", 'Returns', 'to', 'Vancouver', 'on', 'January', '11th', 'http://bit.ly/dbDMs8', '@ls_n', 'perhaps', ',', 'but', 'folks', 'may', 'find', 'something', 'in', 'the', 'gallery', 'that', 'is', 'helpful', 'in', 'their', 'day-to-day', 'work', 'as', 'well', '.', 'Even', 'just', 'to', 'use', 'it', '.', '@Carr0t', 'aye', 'been', 'tonight', '-', 'excellent', 'RT', '@LilTwist', ':', 'RT', 'this', 'if', 'you', 'want', 'me', 'to', 'go']\n",
      "\n",
      "\n",
      "Labels size 46469\n",
      "Corresponding labels of the words in the vocabulary:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo-loc', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-facility', 'I-facility', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-facility', 'I-facility', 'O', 'O', 'O', 'B-movie', 'I-movie', 'O', 'O', 'O', 'B-geo-loc', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "# use the above function to get the data\n",
    "words, tags, sents = read_data(os.path.join(train, \"wnut_ner_evaluation/data/train\"))\n",
    "\n",
    "# test the data if it is coming properly\n",
    "print('Data size %d' % len(words))\n",
    "print(\"Some of the sample words in the vocabulary: \", words[10: 100])\n",
    "\n",
    "print('\\n\\nLabels size %d' % len(tags))\n",
    "print(\"Corresponding labels of the words in the vocabulary: \", tags[10: 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to build a formatted dataset from the list of words \n",
    "# so that the context of the words are taken into consideration\n",
    "\n",
    "def build_dataset(words):\n",
    "    \n",
    "    \"\"\" build a dataset from the list of words \n",
    "    \n",
    "        input: list of words\n",
    "        output: the formatted data, count, dictionary (map), reverse_dictionary\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    vocabulary_size = len(words)  # size of the dictionary to be formed\n",
    "    \n",
    "    # form the dictionary\n",
    "    count = [] \n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "        \n",
    "    # create a list from the dictionary\n",
    "    data = list()\n",
    "    for word in words:       \n",
    "        index = dictionary[word]\n",
    "        data.append(index)\n",
    "  \n",
    "    # a reverse dictionary for mapping the words to their unique id\n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    \n",
    "    return data, count, dictionary, reverse_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words [('when', 283), ('?', 275), ('i', 254), ('day', 253), ('time', 243), ('at', 233), ('be', 220), ('tonight', 209), ('that', 208), ('me', 208)]\n",
      "Sample data [9114, 5971, 84, 49, 26, 46, 231, 95, 132, 1815, 29, 6665, 2924, 12, 102, 135, 3, 1071, 0, 78]\n",
      "what the data corresponds to: \n",
      "@SammieLynnsMom @tg10781 they will be all done by Sunday trust me *wink* Made it back home to GA . It \n"
     ]
    }
   ],
   "source": [
    "# use the above function to convert the list of words into a well formatted dict\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(words)\n",
    "print('Most common words', count[20:30])\n",
    "print('Sample data', data[:20])\n",
    "del words  # Hint to reduce memory.\n",
    "\n",
    "# naive way for constructing the tweets from the dict:\n",
    "print(\"what the data corresponds to: \")\n",
    "string = \"\"\n",
    "for datum in data[:20]:\n",
    "    string += reverse_dictionary[datum] + \" \"\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
